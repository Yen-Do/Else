{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n<h1 align=\"center\"><font size=\"5\">Classification with Python</font></h1>\n","metadata":{}},{"cell_type":"markdown","source":"# Instructions\n","metadata":{}},{"cell_type":"markdown","source":"In this notebook, you will  practice all the classification algorithms that we have learned in this course.\n\nBelow, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n\nWe will use some of the algorithms taught in the course, specifically:\n\n1.  Linear Regression\n2.  KNN\n3.  Decision Trees\n4.  Logistic Regression\n5.  SVM\n\nWe will evaluate our models using:\n\n1.  Accuracy Score\n2.  Jaccard Index\n3.  F1-Score\n4.  LogLoss\n5.  Mean Absolute Error\n6.  Mean Squared Error\n7.  R2-Score\n\nFinally, you will use your models to generate the report at the end.\n","metadata":{}},{"cell_type":"markdown","source":"# About The Dataset\n","metadata":{}},{"cell_type":"markdown","source":"The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n\nThe dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","metadata":{}},{"cell_type":"markdown","source":"This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n\n| Field         | Description                                           | Unit            | Type   |\n| ------------- | ----------------------------------------------------- | --------------- | ------ |\n| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n| Location      | Location of the Observation                           | Location        | object |\n| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n| RainToday     | If there was rain today                               | Yes/No          | object |\n| RISK_MM       | Amount of rain tomorrow                               | Millimeters     | float  |\n| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n\nColumn definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n","metadata":{}},{"cell_type":"markdown","source":"## **Import the required libraries**\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nimport numpy as np\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport sklearn.metrics as metrics","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:01.640866Z","iopub.execute_input":"2022-10-19T23:06:01.641358Z","iopub.status.idle":"2022-10-19T23:06:02.244337Z","shell.execute_reply.started":"2022-10-19T23:06:01.641265Z","shell.execute_reply":"2022-10-19T23:06:02.243167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing the Dataset\n","metadata":{}},{"cell_type":"code","source":"!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:02.246763Z","iopub.execute_input":"2022-10-19T23:06:02.247258Z","iopub.status.idle":"2022-10-19T23:06:04.814456Z","shell.execute_reply.started":"2022-10-19T23:06:02.247205Z","shell.execute_reply":"2022-10-19T23:06:04.813087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"./Weather_Data.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.816846Z","iopub.execute_input":"2022-10-19T23:06:04.817225Z","iopub.status.idle":"2022-10-19T23:06:04.873461Z","shell.execute_reply.started":"2022-10-19T23:06:04.817188Z","shell.execute_reply":"2022-10-19T23:06:04.872192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing\n","metadata":{}},{"cell_type":"markdown","source":"#### One Hot Encoding\n","metadata":{}},{"cell_type":"markdown","source":"First, we need to perform one hot encoding to convert categorical variables to binary variables.\n","metadata":{}},{"cell_type":"code","source":"df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.87698Z","iopub.execute_input":"2022-10-19T23:06:04.877382Z","iopub.status.idle":"2022-10-19T23:06:04.895508Z","shell.execute_reply.started":"2022-10-19T23:06:04.877339Z","shell.execute_reply":"2022-10-19T23:06:04.893943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n","metadata":{}},{"cell_type":"code","source":"df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.897496Z","iopub.execute_input":"2022-10-19T23:06:04.897906Z","iopub.status.idle":"2022-10-19T23:06:04.908837Z","shell.execute_reply.started":"2022-10-19T23:06:04.89787Z","shell.execute_reply":"2022-10-19T23:06:04.907534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Data and Test Data\n","metadata":{}},{"cell_type":"markdown","source":"Now, we set our 'features' or x values and our Y or target variable.\n","metadata":{}},{"cell_type":"code","source":"df_sydney_processed.drop('Date',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.910627Z","iopub.execute_input":"2022-10-19T23:06:04.911545Z","iopub.status.idle":"2022-10-19T23:06:04.919766Z","shell.execute_reply.started":"2022-10-19T23:06:04.911504Z","shell.execute_reply":"2022-10-19T23:06:04.918427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sydney_processed = df_sydney_processed.astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.921719Z","iopub.execute_input":"2022-10-19T23:06:04.922194Z","iopub.status.idle":"2022-10-19T23:06:04.935418Z","shell.execute_reply.started":"2022-10-19T23:06:04.922158Z","shell.execute_reply":"2022-10-19T23:06:04.934443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\nY = df_sydney_processed['RainTomorrow']","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.937019Z","iopub.execute_input":"2022-10-19T23:06:04.938128Z","iopub.status.idle":"2022-10-19T23:06:04.95387Z","shell.execute_reply.started":"2022-10-19T23:06:04.938083Z","shell.execute_reply":"2022-10-19T23:06:04.952875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Linear Regression\n","metadata":{}},{"cell_type":"markdown","source":"#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot\n\nx_train, x_test, y_train, y_test = train_test_split( features,Y, test_size=0.2, random_state=10)\nprint ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.955501Z","iopub.execute_input":"2022-10-19T23:06:04.955911Z","iopub.status.idle":"2022-10-19T23:06:04.970761Z","shell.execute_reply.started":"2022-10-19T23:06:04.955869Z","shell.execute_reply":"2022-10-19T23:06:04.969458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot\n\nLinearReg = LinearRegression()\nx = np.asanyarray(x_train)\ny = np.asanyarray(y_train)\nLinearReg.fit (x, y)\n# The coefficients\nprint ('Coefficients: ', LinearReg.coef_)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:04.974876Z","iopub.execute_input":"2022-10-19T23:06:04.976171Z","iopub.status.idle":"2022-10-19T23:06:05.003857Z","shell.execute_reply.started":"2022-10-19T23:06:04.976127Z","shell.execute_reply":"2022-10-19T23:06:05.002222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot\npredictions = LinearReg.predict(x_test)\nx = np.asanyarray(x_test)\ny = np.asanyarray(y_test)\nprint(\"Residual sum of squares: %.2f\"\n      % np.mean((predictions - y) ** 2))\n\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % LinearReg.score(x, y))","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.006075Z","iopub.execute_input":"2022-10-19T23:06:05.006963Z","iopub.status.idle":"2022-10-19T23:06:05.035053Z","shell.execute_reply.started":"2022-10-19T23:06:05.006908Z","shell.execute_reply":"2022-10-19T23:06:05.033726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nLinearRegression_MAE = np.mean(np.absolute(predictions - y_test))\nLinearRegression_MSE = np.mean((predictions -y_test)**2)\nLinearRegression_R2 = r2_score(y_test, predictions)\nprint(\"Mean absolute error: %.2f\" % LinearRegression_MAE)\nprint(\"Residual sum of squares (MSE): %.2f\" % LinearRegression_MSE)\nprint(\"R2-score: %.2f\" % LinearRegression_R2 )","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.037178Z","iopub.execute_input":"2022-10-19T23:06:05.038117Z","iopub.status.idle":"2022-10-19T23:06:05.054049Z","shell.execute_reply.started":"2022-10-19T23:06:05.038063Z","shell.execute_reply":"2022-10-19T23:06:05.052583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.057095Z","iopub.execute_input":"2022-10-19T23:06:05.058196Z","iopub.status.idle":"2022-10-19T23:06:05.06443Z","shell.execute_reply.started":"2022-10-19T23:06:05.058142Z","shell.execute_reply":"2022-10-19T23:06:05.06312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict = {'error_type':['LinearRegression_MAE','LinearRegression_MSE','LinearRegression_R2'],\n        \n        'value':[LinearRegression_MAE,LinearRegression_MSE,LinearRegression_R2]}","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.070526Z","iopub.execute_input":"2022-10-19T23:06:05.077939Z","iopub.status.idle":"2022-10-19T23:06:05.091344Z","shell.execute_reply.started":"2022-10-19T23:06:05.072963Z","shell.execute_reply":"2022-10-19T23:06:05.089399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tabulate import tabulate\nReport = pd.DataFrame(dict)\nprint(tabulate(Report, headers = 'keys', tablefmt = 'psql'))","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.094361Z","iopub.execute_input":"2022-10-19T23:06:05.095749Z","iopub.status.idle":"2022-10-19T23:06:05.126061Z","shell.execute_reply.started":"2022-10-19T23:06:05.095672Z","shell.execute_reply":"2022-10-19T23:06:05.124653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN\n","metadata":{}},{"cell_type":"markdown","source":"#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.132341Z","iopub.execute_input":"2022-10-19T23:06:05.138672Z","iopub.status.idle":"2022-10-19T23:06:05.148368Z","shell.execute_reply.started":"2022-10-19T23:06:05.138579Z","shell.execute_reply":"2022-10-19T23:06:05.146432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train Model \nk = 4\nneigh = KNeighborsClassifier(n_neighbors = k).fit(x_train,y_train)\nneigh","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.151102Z","iopub.execute_input":"2022-10-19T23:06:05.151987Z","iopub.status.idle":"2022-10-19T23:06:05.171502Z","shell.execute_reply.started":"2022-10-19T23:06:05.151936Z","shell.execute_reply":"2022-10-19T23:06:05.170211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.173242Z","iopub.execute_input":"2022-10-19T23:06:05.174417Z","iopub.status.idle":"2022-10-19T23:06:05.180382Z","shell.execute_reply.started":"2022-10-19T23:06:05.174365Z","shell.execute_reply":"2022-10-19T23:06:05.178747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = neigh.predict(x_test)\npredictions[0:5]","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.181844Z","iopub.execute_input":"2022-10-19T23:06:05.182416Z","iopub.status.idle":"2022-10-19T23:06:05.320927Z","shell.execute_reply.started":"2022-10-19T23:06:05.182373Z","shell.execute_reply":"2022-10-19T23:06:05.319675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.322959Z","iopub.execute_input":"2022-10-19T23:06:05.323743Z","iopub.status.idle":"2022-10-19T23:06:05.328876Z","shell.execute_reply.started":"2022-10-19T23:06:05.323691Z","shell.execute_reply":"2022-10-19T23:06:05.327637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\nKNN_JaccardIndex = metrics.jaccard_score(y_test, predictions)\nKNN_F1_Score = metrics.f1_score(y_test, predictions)\nKNN_Log_Loss = metrics.log_loss(y_test, predictions)\nprint(\"KNN Accuracy Score: \",KNN_Accuracy_Score)\nprint(\"KNN_JaccardIndex: \",KNN_JaccardIndex)\nprint(\"KNN F1 score : \", KNN_F1_Score)\nprint(\"KNN Log Loss : \", KNN_Log_Loss)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.331027Z","iopub.execute_input":"2022-10-19T23:06:05.331823Z","iopub.status.idle":"2022-10-19T23:06:05.349122Z","shell.execute_reply.started":"2022-10-19T23:06:05.331746Z","shell.execute_reply":"2022-10-19T23:06:05.347873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree\n","metadata":{}},{"cell_type":"markdown","source":"#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.351005Z","iopub.execute_input":"2022-10-19T23:06:05.351892Z","iopub.status.idle":"2022-10-19T23:06:05.357216Z","shell.execute_reply.started":"2022-10-19T23:06:05.35184Z","shell.execute_reply":"2022-10-19T23:06:05.35606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nTree.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.359267Z","iopub.execute_input":"2022-10-19T23:06:05.360133Z","iopub.status.idle":"2022-10-19T23:06:05.390981Z","shell.execute_reply.started":"2022-10-19T23:06:05.360085Z","shell.execute_reply":"2022-10-19T23:06:05.389743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.392463Z","iopub.execute_input":"2022-10-19T23:06:05.393188Z","iopub.status.idle":"2022-10-19T23:06:05.398811Z","shell.execute_reply.started":"2022-10-19T23:06:05.393139Z","shell.execute_reply":"2022-10-19T23:06:05.397511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = Tree.predict(x_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.400987Z","iopub.execute_input":"2022-10-19T23:06:05.401845Z","iopub.status.idle":"2022-10-19T23:06:05.416998Z","shell.execute_reply.started":"2022-10-19T23:06:05.401754Z","shell.execute_reply":"2022-10-19T23:06:05.415445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.419086Z","iopub.execute_input":"2022-10-19T23:06:05.420487Z","iopub.status.idle":"2022-10-19T23:06:05.430262Z","shell.execute_reply.started":"2022-10-19T23:06:05.420384Z","shell.execute_reply":"2022-10-19T23:06:05.429033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tree_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\nTree_JaccardIndex = metrics.jaccard_score(y_test, predictions)\nTree_F1_Score = metrics.f1_score(y_test, predictions)\nTree_Log_Loss = metrics.log_loss(y_test, predictions)\nprint(\"Tree accur_acy score: \", Tree_Accuracy_Score)\nprint(\"Tree JaccardIndex : \", Tree_JaccardIndex)\nprint(\"Tree_F1_Score : \", Tree_F1_Score)\nprint(\"Tree Log Loss : \", Tree_Log_Loss)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.432175Z","iopub.execute_input":"2022-10-19T23:06:05.433039Z","iopub.status.idle":"2022-10-19T23:06:05.451531Z","shell.execute_reply.started":"2022-10-19T23:06:05.432988Z","shell.execute_reply":"2022-10-19T23:06:05.450136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression\n","metadata":{}},{"cell_type":"markdown","source":"#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.45788Z","iopub.execute_input":"2022-10-19T23:06:05.458265Z","iopub.status.idle":"2022-10-19T23:06:05.463019Z","shell.execute_reply.started":"2022-10-19T23:06:05.458233Z","shell.execute_reply":"2022-10-19T23:06:05.461876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size = 0.2, random_state =1)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.464388Z","iopub.execute_input":"2022-10-19T23:06:05.465845Z","iopub.status.idle":"2022-10-19T23:06:05.480417Z","shell.execute_reply.started":"2022-10-19T23:06:05.465762Z","shell.execute_reply":"2022-10-19T23:06:05.479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.482264Z","iopub.execute_input":"2022-10-19T23:06:05.482635Z","iopub.status.idle":"2022-10-19T23:06:05.492217Z","shell.execute_reply.started":"2022-10-19T23:06:05.482603Z","shell.execute_reply":"2022-10-19T23:06:05.490759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.494045Z","iopub.execute_input":"2022-10-19T23:06:05.49456Z","iopub.status.idle":"2022-10-19T23:06:05.503202Z","shell.execute_reply.started":"2022-10-19T23:06:05.494524Z","shell.execute_reply":"2022-10-19T23:06:05.502098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = LogisticRegression(C=0.01, solver='liblinear').fit(x_train,y_train)\nLR","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.505243Z","iopub.execute_input":"2022-10-19T23:06:05.505742Z","iopub.status.idle":"2022-10-19T23:06:05.55773Z","shell.execute_reply.started":"2022-10-19T23:06:05.505694Z","shell.execute_reply":"2022-10-19T23:06:05.556463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q14) Now, use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.559251Z","iopub.execute_input":"2022-10-19T23:06:05.559636Z","iopub.status.idle":"2022-10-19T23:06:05.565214Z","shell.execute_reply.started":"2022-10-19T23:06:05.559601Z","shell.execute_reply":"2022-10-19T23:06:05.564166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = LR.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.566571Z","iopub.execute_input":"2022-10-19T23:06:05.567952Z","iopub.status.idle":"2022-10-19T23:06:05.580994Z","shell.execute_reply.started":"2022-10-19T23:06:05.567903Z","shell.execute_reply":"2022-10-19T23:06:05.579243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q15) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code, Execute and take the Screenshot","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.583575Z","iopub.execute_input":"2022-10-19T23:06:05.584695Z","iopub.status.idle":"2022-10-19T23:06:05.59551Z","shell.execute_reply.started":"2022-10-19T23:06:05.584638Z","shell.execute_reply":"2022-10-19T23:06:05.593821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR_Accuracy_Score = metrics.accuracy_score(y_test,predictions)\nLR_JaccardIndex = metrics.jaccard_score(y_test,predictions)\nLR_F1_Score = metrics.f1_score(y_test,predictions)\nLR_Log_Loss = metrics.log_loss(y_test, predictions)\nprint(\"LR accuracy score: \", LR_Accuracy_Score)\nprint(\"LR JaccardIndex : \", LR_JaccardIndex)\nprint(\"LR F1 Score : \", LR_F1_Score)\nprint(\"LR Log Loss : \", LR_Log_Loss)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.598656Z","iopub.execute_input":"2022-10-19T23:06:05.599929Z","iopub.status.idle":"2022-10-19T23:06:05.628635Z","shell.execute_reply.started":"2022-10-19T23:06:05.599851Z","shell.execute_reply":"2022-10-19T23:06:05.626818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVM\n","metadata":{}},{"cell_type":"markdown","source":"#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.631328Z","iopub.execute_input":"2022-10-19T23:06:05.632368Z","iopub.status.idle":"2022-10-19T23:06:05.640124Z","shell.execute_reply.started":"2022-10-19T23:06:05.632292Z","shell.execute_reply":"2022-10-19T23:06:05.638374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM = svm.SVC(kernel='linear')\nSVM.fit(x_train, y_train) ","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:05.642718Z","iopub.execute_input":"2022-10-19T23:06:05.643843Z","iopub.status.idle":"2022-10-19T23:06:08.32454Z","shell.execute_reply.started":"2022-10-19T23:06:05.643763Z","shell.execute_reply":"2022-10-19T23:06:08.323275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n","metadata":{}},{"cell_type":"code","source":"#Enter Your Code Below, Execute, and Save the Screenshot of the Final Output","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:08.325841Z","iopub.execute_input":"2022-10-19T23:06:08.326189Z","iopub.status.idle":"2022-10-19T23:06:08.331364Z","shell.execute_reply.started":"2022-10-19T23:06:08.326159Z","shell.execute_reply":"2022-10-19T23:06:08.330107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = SVM.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:08.332964Z","iopub.execute_input":"2022-10-19T23:06:08.333571Z","iopub.status.idle":"2022-10-19T23:06:08.373332Z","shell.execute_reply.started":"2022-10-19T23:06:08.333531Z","shell.execute_reply":"2022-10-19T23:06:08.372245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n","metadata":{}},{"cell_type":"code","source":"SVM_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\nSVM_JaccardIndex = metrics.jaccard_score(y_test, predictions)\nSVM_F1_Score = metrics.f1_score(y_test, predictions)\nSVM_Log_Loss = metrics.log_loss(y_test, predictions)\nprint(\"SVM accuracy score : \", SVM_Accuracy_Score)\nprint(\"SVM jaccardIndex : \", SVM_JaccardIndex)\nprint(\"SVM F1_score : \", SVM_F1_Score)\nprint(\"SVM Log Loss : \", SVM_Log_Loss)","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:08.374946Z","iopub.execute_input":"2022-10-19T23:06:08.375317Z","iopub.status.idle":"2022-10-19T23:06:08.389549Z","shell.execute_reply.started":"2022-10-19T23:06:08.375277Z","shell.execute_reply":"2022-10-19T23:06:08.388374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Report\n","metadata":{}},{"cell_type":"markdown","source":"#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n\n\\*LogLoss is only for Logistic Regression Model\n","metadata":{}},{"cell_type":"code","source":"d = {'KNN':[KNN_Accuracy_Score,KNN_JaccardIndex,KNN_F1_Score,KNN_Log_Loss],\n     'Tree':[Tree_Accuracy_Score, Tree_JaccardIndex, Tree_F1_Score, Tree_Log_Loss],\n     'LR':[LR_Accuracy_Score, LR_JaccardIndex, LR_F1_Score,LR_Log_Loss],\n     'SVM':[SVM_Accuracy_Score, SVM_JaccardIndex, SVM_F1_Score, SVM_Log_Loss]}\nReport = pd.DataFrame(data=d, index = ['Accuracy','Jaccard Index','F1-Score', 'LogLoss'])\nprint(tabulate(Report, headers = 'keys', tablefmt = 'psql'))","metadata":{"execution":{"iopub.status.busy":"2022-10-19T23:06:08.390815Z","iopub.execute_input":"2022-10-19T23:06:08.391158Z","iopub.status.idle":"2022-10-19T23:06:08.400832Z","shell.execute_reply.started":"2022-10-19T23:06:08.391127Z","shell.execute_reply":"2022-10-19T23:06:08.399584Z"},"trusted":true},"execution_count":null,"outputs":[]}]}